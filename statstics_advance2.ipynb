{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82546bee-ccc8-4cdd-be94-b7f2bf67734d",
   "metadata": {},
   "source": [
    "Q1: What are the Probability Mass Function (PMF) and Probability Density Function (PDF)? Explain with\n",
    "an example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8611e7bd-d0cc-4de6-9348-ddff7fb325f0",
   "metadata": {},
   "source": [
    "Ans--> Probability Mass Function (PMF) and Probability Density Function (PDF) are two common mathematical tools used to describe the probability distribution of a random variable.\n",
    "\n",
    "A Probability Mass Function (PMF) is a function that describes the probability distribution of a discrete random variable. It assigns a probability to each possible value that the random variable can take. The sum of probabilities for all possible values must equal 1. For example, consider a coin that is tossed three times. The possible outcomes are {HHH, HHT, HTH, HTT, THH, THT, TTH, TTT}. The PMF of the number of heads that appear can be calculated as follows:\n",
    "\n",
    "Number of heads (X) 0 1 2 3\n",
    "Probability (P(X)) 1/8 3/8 3/8 1/8\n",
    "obability of each possible number of heads that can appear in the three tosses of the coin.\n",
    "\n",
    "On the other hand, a Probability Density Function (PDF) is a function that describes the probability distribution of a continuous random variable. It assigns a probability density to each possible value that the random variable can take. The area under the curve of the PDF over a certain range of values represents the probability of the random variable taking a value within that range. For example, the PDF of the height of adult males in the United States can be represented using a normal distribution. The PDF of the normal distribution is given by the following equation:\n",
    "\n",
    "f(x) = (1/σ√2π) * e^(-(x-μ)²/2σ²)\n",
    "\n",
    "where x is the height, μ is the mean height, σ is the standard deviation of height, and e is the mathematical constant. The PDF shows the probability density of the height at each possible value of x.\n",
    "\n",
    "In summary, the PMF is used for discrete random variables while the PDF is used for continuous random variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa089a2-286c-4f46-8df3-982be80d03f3",
   "metadata": {},
   "source": [
    "Q2: What is Cumulative Density Function (CDF)? Explain with an example. Why CDF is used?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "731a0d3e-0df0-4ffb-9f21-0200feec9baf",
   "metadata": {},
   "source": [
    "Ans--> A Cumulative Density Function (CDF) is a function that gives the probability that a random variable X is less than or equal to a certain value x. The CDF is defined as the integral of the Probability Density Function (PDF) or the sum of the Probability Mass Function (PMF) up to the point x. Mathematically, the CDF is denoted by F(x) and is expressed as:\n",
    "\n",
    "F(x) = P(X ≤ x)\n",
    "\n",
    "where X is the random variable.\n",
    "\n",
    "The CDF can be used to determine the probability of a random variable taking a value less than or equal to a certain value, as well as the probability of it taking a value within a certain range. It is also useful in finding percentiles of the distribution, which are values that divide the distribution into equal parts.\n",
    "\n",
    "For example, let's consider a standard normal distribution with a mean of 0 and a standard deviation of 1. The PDF of the standard normal distribution is denoted by φ(x) and is given by:\n",
    "\n",
    "φ(x) = (1/√2π) * e^(-x^2/2)\n",
    "\n",
    "The CDF of the standard normal distribution, denoted by Φ(x), is the integral of the PDF from negative infinity to x:\n",
    "\n",
    "Φ(x) = ∫[-∞, x] φ(t) dt\n",
    "\n",
    "Using a table or a calculator, we can find the probability that a random variable X following a standard normal distribution is less than or equal to a certain value x. For example, the probability that X is less than or equal to 1.96 is:\n",
    "\n",
    "Φ(1.96) = 0.975\n",
    "\n",
    "This means that there is a 97.5% chance that a random variable following a standard normal distribution will be less than or equal to 1.96.\n",
    "\n",
    "The CDF is an important tool in probability and statistics because it provides a complete description of the distribution of a random variable. It helps in making predictions and in statistical inference, which involves drawing conclusions about a population based on a sample."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e21e5f8-6ddd-4ad1-b112-4ccaecf55152",
   "metadata": {},
   "source": [
    "Q3: What are some examples of situations where the normal distribution might be used as a model?\n",
    "Explain how the parameters of the normal distribution relate to the shape of the distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5bc644b-b70a-4832-945c-dac2d460388c",
   "metadata": {},
   "source": [
    "Ans--> The normal distribution is a probability distribution that is commonly used to model a wide variety of phenomena in various fields such as finance, economics, physics, and engineering. The normal distribution is often used when the data follows a bell-shaped curve, where the majority of the data falls near the mean and the distribution is symmetrical.\n",
    "\n",
    "Here are some examples of situations where the normal distribution might be used as a model:\n",
    "\n",
    "1.Height and weight of individuals in a population\n",
    "\n",
    "2.Scores on standardized tests such as the SAT or GRE\n",
    "\n",
    "3.The amount of time spent waiting in a queue\n",
    "\n",
    "4.The returns on financial assets such as stocks and bonds\n",
    "\n",
    "5.The errors in measurement of a physical quantity such as length, weight or time.\n",
    "\n",
    "The normal distribution is defined by two parameters: the mean (μ) and the standard deviation (σ). The mean represents the center of the distribution, while the standard deviation represents the spread or the variability of the distribution. The value of μ determines the location of the peak of the curve, while the value of σ determines the width of the curve. Specifically, increasing the value of σ results in a wider and flatter curve, while decreasing the value of σ results in a narrower and taller curve.\n",
    "\n",
    "The normal distribution has several properties that make it a useful model for a wide range of phenomena. One important property is the Central Limit Theorem (CLT), which states that the sum of a large number of independent and identically distributed random variables, each with finite mean and variance, will be approximately normally distributed, regardless of the underlying distribution of the individual variables. This makes the normal distribution a good model for many real-world phenomena.\n",
    "\n",
    "In summary, the normal distribution is a versatile and widely used probability distribution that can be used to model a wide range of phenomena. The parameters of the normal distribution, namely the mean and standard deviation, determine the location, shape and spread of the distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab451d9-e56d-4778-b314-945feeb70176",
   "metadata": {},
   "source": [
    "Q4: Explain the importance of Normal Distribution. Give a few real-life examples of Normal\n",
    "Distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6174ca4-808b-4f6f-be93-24987bb1f214",
   "metadata": {},
   "source": [
    "Ans--> The normal distribution is an important probability distribution that is widely used in statistics and data analysis. It is important because of its mathematical properties, which make it a useful model for many real-world phenomena. Some of the key features of the normal distribution include:\n",
    "\n",
    "1.Symmetry: The normal distribution is symmetric around the mean, which means that half of the data is on each side of the mean.\n",
    "\n",
    "2.Central tendency: The mean, median, and mode of the normal distribution are all equal, which makes it a good model for phenomena that have a well-defined center or average value.\n",
    "\n",
    "3.Universality: The normal distribution is a limiting distribution, which means that it is often a good approximation for the distribution of many different types of data, regardless of their underlying distribution.\n",
    "\n",
    "4.The Central Limit Theorem: The normal distribution is a key component of the Central Limit Theorem, which states that the distribution of the mean of a large number of independent random variables will be approximately normally distributed, regardless of the distribution of the individual variables.\n",
    "\n",
    "Some real-life examples of the normal distribution include:\n",
    "\n",
    "1.Height: The height of people in a population often follows a normal distribution, with most people around the average height and fewer people at the extreme ends of the distribution.\n",
    "\n",
    "2.Weight: The weight of people in a population often follows a normal distribution, with most people around the average weight and fewer people at the extreme ends of the distribution.\n",
    "\n",
    "3.Test Scores: The scores on standardized tests like the SAT and ACT often follow a normal distribution, with most people scoring around the average and fewer people at the extreme high and low ends of the distribution.\n",
    "\n",
    "4.IQ Scores: The distribution of IQ scores in the population is often modeled by a normal distribution, with most people having average IQ scores and fewer people at the extreme high and low ends of the distribution.\n",
    "\n",
    "5.Stock Prices: The daily returns on stocks often follow a normal distribution, with most days having small gains or losses and fewer days with large gains or losses.\n",
    "\n",
    "In summary, the normal distribution is an important probability distribution that is widely used in statistics and data analysis. Its mathematical properties and universality make it a useful model for many real-world phenomena, and it is used to model a wide range of data, including height, weight, test scores, IQ scores, and stock prices, among others."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f842dd2-0c23-4e5c-963b-57d2f92508c7",
   "metadata": {},
   "source": [
    "Q5: What is Bernaulli Distribution? Give an Example. What is the difference between Bernoulli\n",
    "Distribution and Binomial Distribution?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e41ca33-e1fe-474f-ba9f-46f74a26ab39",
   "metadata": {},
   "source": [
    "Ans--> The Bernoulli distribution is a discrete probability distribution that describes the outcome of a single binary experiment, such as flipping a coin or the success or failure of a single trial in a series of trials. It is named after Swiss mathematician Jacob Bernoulli, who used it to study the outcomes of repeated coin tosses.\n",
    "\n",
    "The Bernoulli distribution has two possible outcomes, typically labeled 0 and 1, and is characterized by a single parameter, p, which represents the probability of success, or the probability that the outcome is 1. The probability of failure, or the probability that the outcome is 0, is equal to 1-p.\n",
    "\n",
    "An example of the Bernoulli distribution is flipping a fair coin, where p=0.5 represents the probability of getting heads, and 1-p=0.5 represents the probability of getting tails. In this case, the Bernoulli distribution is used to model the outcome of a single coin flip, where the outcome is either heads (1) or tails (0).\n",
    "\n",
    "The binomial distribution, on the other hand, describes the probability distribution of the number of successes in a fixed number of independent Bernoulli trials. In other words, it describes the probability of getting a certain number of successes, k, in n independent trials, each with probability of success p. The binomial distribution has two parameters, n and p.\n",
    "\n",
    "The key difference between the Bernoulli distribution and the binomial distribution is that the Bernoulli distribution describes the outcome of a single trial, while the binomial distribution describes the outcome of multiple trials. The Bernoulli distribution can be thought of as a special case of the binomial distribution, where n=1.\n",
    "\n",
    "For example, let's say we flip a fair coin 10 times and want to know the probability of getting exactly 5 heads. We can model this using the binomial distribution with parameters n=10 and p=0.5. Each individual coin flip is a Bernoulli trial, and the binomial distribution describes the probability of getting exactly 5 successes in 10 independent trials.\n",
    "\n",
    "In summary, the Bernoulli distribution is a discrete probability distribution that describes the outcome of a single binary experiment, while the binomial distribution describes the probability distribution of the number of successes in a fixed number of independent Bernoulli trials. The Bernoulli distribution can be thought of as a special case of the binomial distribution where n=1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a482b2-568c-454c-996d-64ce8f1fa99b",
   "metadata": {},
   "source": [
    "Q6. Consider a dataset with a mean of 50 and a standard deviation of 10. If we assume that the dataset\n",
    "is normally distributed, what is the probability that a randomly selected observation will be greater\n",
    "than 60? Use the appropriate formula and show your calculations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d40ca00-d195-4ec7-be0a-ce98d95d2fee",
   "metadata": {},
   "source": [
    "Ans--> To calculate the probability that a randomly selected observation will be greater than 60, we need to use the cumulative distribution function (CDF) of the normal distribution. Specifically, we want to find the probability of observing a value greater than 60, given a normal distribution with mean μ = 50 and standard deviation σ = 10.\n",
    "\n",
    "Using the formula for the Z-score, we can standardize the value of 60 to a standard normal distribution with a mean of 0 and standard deviation of 1:\n",
    "\n",
    "z = (x - μ) / σ\n",
    "z = (60 - 50) / 10\n",
    "z = 1\n",
    "\n",
    "Now, we can use a standard normal distribution table or a calculator to find the area under the standard normal distribution curve to the right of z = 1. This represents the probability of observing a value greater than 60.\n",
    "\n",
    "The table or calculator will give us the cumulative probability, which we can subtract from 1 to get the probability of the complement event, which is the probability of observing a value greater than 60:\n",
    "\n",
    "P(X > 60) = 1 - P(Z ≤ 1)\n",
    "\n",
    "Using a standard normal distribution table or calculator, we find that P(Z ≤ 1) = 0.8413.\n",
    "\n",
    "Therefore, P(X > 60) = 1 - 0.8413 = 0.1587.\n",
    "\n",
    "Thus, the probability that a randomly selected observation from the dataset will be greater than 60 is approximately 0.1587 or 15.87%."
   ]
  },
  {
   "cell_type": "raw",
   "id": "63ed08ee-e37d-466d-bb8d-e3aab8caf02c",
   "metadata": {},
   "source": [
    "Q7: Explain uniform Distribution with an example."
   ]
  },
  {
   "cell_type": "raw",
   "id": "732de6ad-8aba-43bf-afe2-a2518b4b88df",
   "metadata": {},
   "source": [
    "Ans--> The uniform distribution is a continuous probability distribution that describes a random variable with equal probability of taking any value within a given range. In other words, the probability of the random variable falling within any subinterval of the given range is proportional to the length of that subinterval. The uniform distribution is often used as a simple model for random variables that have no preference for any particular value in a given range.\n",
    "\n",
    "An example of the uniform distribution is rolling a fair six-sided die. The possible outcomes are the integers 1 through 6, each with equal probability of occurring. The probability density function of a continuous uniform distribution over the interval [a, b] is given by:\n",
    "\n",
    "f(x) = 1 / (b - a) for a ≤ x ≤ b\n",
    "f(x) = 0 otherwise\n",
    "\n",
    "where f(x) is the probability density function, and a and b are the lower and upper bounds of the range.\n",
    "\n",
    "For instance, suppose we have a random variable X that represents the time (in minutes) that it takes for a customer to complete a purchase at a store. If we assume that the purchase times are uniformly distributed between 2 and 10 minutes, then the probability density function of X can be expressed as:\n",
    "\n",
    "f(x) = 1 / (10 - 2) for 2 ≤ x ≤ 10\n",
    "f(x) = 0 otherwise\n",
    "\n",
    "This means that any value of X between 2 and 10 minutes is equally likely to occur, and the probability of any subinterval within this range is proportional to its length.\n",
    "\n",
    "In summary, the uniform distribution is a probability distribution that describes a random variable with equal probability of taking any value within a given range. It is often used as a simple model for random variables that have no preference for any particular value in a given range."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f968d7-7702-4891-a516-471a7c9b6b17",
   "metadata": {},
   "source": [
    "Q8: What is the z score? State the importance of the z score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59db61a8-8aeb-4de2-b5cd-5f1ae53aa280",
   "metadata": {},
   "source": [
    "Ans--> The z-score (also known as the standard score) is a statistical measure that indicates how many standard deviations a given data point is from the mean of a population or a sample. The z-score is calculated as the difference between the value of a data point and the mean of the population or sample, divided by the standard deviation of the population or sample.\n",
    "\n",
    "The formula for calculating the z-score is:\n",
    "\n",
    "z = (x - μ) / σ\n",
    "\n",
    "where x is the value of the data point, μ is the mean of the population or sample, and σ is the standard deviation of the population or sample.\n",
    "\n",
    "The z-score is important because it allows us to compare values from different normal distributions on a standard scale. A positive z-score indicates that a data point is above the mean, while a negative z-score indicates that a data point is below the mean. The magnitude of the z-score tells us how far the data point is from the mean in terms of standard deviations.\n",
    "\n",
    "The z-score is also used to calculate probabilities associated with the normal distribution. For example, we can use a z-score table or calculator to find the probability of observing a value less than or greater than a given data point in a normal distribution.\n",
    "\n",
    "In summary, the z-score is a standardized measure of how many standard deviations a data point is from the mean of a population or sample. It allows us to compare values from different normal distributions on a standard scale and calculate probabilities associated with the normal distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae533f17-d158-4c28-98f1-594c978dc0e4",
   "metadata": {},
   "source": [
    "Q9: What is Central Limit Theorem? State the significance of the Central Limit Theorem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88016854-5e0b-4e7a-9ab3-5a055586c4d8",
   "metadata": {},
   "source": [
    "Ans--> The Central Limit Theorem (CLT) is a fundamental concept in statistics that states that as the sample size of independent and identically distributed random variables increases, the sampling distribution of the sample means approaches a normal distribution, regardless of the underlying distribution of the population.\n",
    "\n",
    "In other words, the CLT asserts that the distribution of the sample means from a large sample of independent and identically distributed random variables will approximate a normal distribution, regardless of the distribution of the individual random variables themselves. This means that the mean of the sample means will be equal to the population mean and the standard deviation of the sample means will be equal to the standard deviation of the population divided by the square root of the sample size.\n",
    "\n",
    "The significance of the Central Limit Theorem lies in its practical applications. The theorem provides a theoretical basis for many statistical techniques used in hypothesis testing and estimation, particularly when dealing with large samples. It allows us to make inferences about a population based on a sample, even if the underlying distribution of the population is unknown or non-normal. This is particularly useful in real-world scenarios where collecting a large sample is often more practical than collecting a sample that is representative of a specific population.\n",
    "\n",
    "Furthermore, the CLT is widely used in the design of experiments and the analysis of data, allowing us to draw more accurate conclusions and make more precise predictions about a population based on a sample."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be3948a1-15dc-452c-9eb3-56874db6f70b",
   "metadata": {},
   "source": [
    "Q10: State the assumptions of the Central Limit Theorem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e210d878-cf2c-463f-b0f0-2d10f6736759",
   "metadata": {},
   "source": [
    "Ans--> The Central Limit Theorem (CLT) has some assumptions that must be met for the theorem to be applicable. These assumptions include:\n",
    "\n",
    "1.Independence: The random variables in the sample must be independent of each other. This means that the value of one random variable should not affect the value of another.\n",
    "\n",
    "2.Sample size: The sample size must be large enough for the CLT to hold. There is no exact number for what constitutes a \"large\" sample size, but a rule of thumb is that the sample size should be greater than or equal to 30.\n",
    "\n",
    "3.Population distribution: The population distribution should have a finite mean (μ) and a finite variance (σ²). The CLT does not require the population distribution to be normal, but it works best for populations that are roughly symmetric and not too skewed.\n",
    "\n",
    "4.Sampling method: The sampling method used to select the sample should be random. This ensures that the sample is representative of the population.\n",
    "\n",
    "If these assumptions are met, then the CLT can be used to approximate the sampling distribution of the sample means. The CLT is a powerful tool in statistics that allows us to make inferences about a population based on a sample, even when the underlying distribution of the population is unknown or non-normal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891d7432-0c59-46f9-90d3-3a00af683ec9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
